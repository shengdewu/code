{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as img\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.python.framework import ops\n",
    "import math\n",
    "import os\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dropout,Input, Cropping2D,merge,Add, Dense, Activation, ZeroPadding2D, SeparableConv2D,BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Lambda,Convolution2D,Conv2DTranspose,UpSampling2D,Subtract,regularizers\n",
    "from keras.models import Model, load_model,Sequential\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.optimizers import SGD\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "import scipy.misc\n",
    "import h5py\n",
    "import matplotlib.image as img\n",
    "from keras.callbacks import ModelCheckpoint,CSVLogger, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import cv2, datetime,sys,glob\n",
    "#os.environ['KERAS_BACKEND']= 'theano'\n",
    "import keras.backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "use_gpu_num = 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "#use cpu only\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_points(file_name=None):\n",
    "    \"\"\"\n",
    "    Read points from .pts file.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    with open(file_name) as file:\n",
    "        line_count = 0\n",
    "        for line in file:\n",
    "            if \"version\" in line or \"points\" in line or \"{\" in line or \"}\" in line:\n",
    "                continue\n",
    "            else:\n",
    "                loc_x, loc_y = line.strip().split(\" \")\n",
    "                points.append([float(loc_x), float(loc_y)])\n",
    "                line_count += 1\n",
    "    return points\n",
    "def draw_landmark_point(image, points):\n",
    "    \"\"\"\n",
    "    Draw landmark point on image.\n",
    "    \"\"\"\n",
    "    for point in points:\n",
    "        cv2.circle(image, (int(point[0]), int(\n",
    "            point[1])), 3, (0, 255, 0), -1, cv2.LINE_AA)\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_facealignment(size=(96,96,3)):\n",
    "    \"\"\"\n",
    "    The model function of the network for face alignment.\n",
    "    Reference:Approaching Human Level Facial Landmark Localization by Deep Learning\n",
    "    \"\"\"\n",
    "    # |== Layer 0: input layer ==|\n",
    "    # Input feature x should be of shape (batch_size, image_width, image_height, color_channels).\n",
    "    # Image shape should be checked for safety reasons at early stages, and could be removed\n",
    "    # before training actually starts.\n",
    "    # assert features['x'].shape[1:] == (\n",
    "    #     IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL), \"Image size does not match.\"\n",
    "    # Default shape of x : (n,128,128,3)\n",
    "    \n",
    "    input_data = Input(size)\n",
    "    # Convolutional layer.\n",
    "    # Computes 32 features using a 3x3 filter with ReLU activation.\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu')(input_data)\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),padding=\"valid\")(x) \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation='relu')(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),padding=\"valid\")(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"valid\",activation='relu')(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"valid\",activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2), strides = (2,2), padding = \"valid\")(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3), strides = (1,1), padding = \"valid\",activation='relu')(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3), strides = (1,1), padding = \"valid\",activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2),strides = (1,1), padding = \"valid\")(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3),strides = (1,1), padding = \"valid\")(x)\n",
    "    x_cut = x\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3),strides = (1,1), padding = \"same\")(x)\n",
    "    x = Add()([x_cut,x])\n",
    "    x_cut = x\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3),strides = (1,1), padding = \"same\",activation='relu')(x)\n",
    "    x = concatenate([x_cut,x])\n",
    "    x = Conv2D(filters = 128, kernel_size = (3,3),strides = (1,1), padding = \"same\",activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256,activation='relu',kernel_regularizer = None)(x)\n",
    "    x = Dense(202, activation = None, use_bias = True)(x)\n",
    "    model = Model(inputs=input_data, outputs=x)\n",
    "    #MSE\n",
    "    return model\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 1e-4\n",
    "    if epoch < 200:\n",
    "        lr = initial_lr\n",
    "    elif epoch < 600:\n",
    "        lr = initial_lr / 2\n",
    "    elif epoch < 1000:\n",
    "        lr = initial_lr / 3\n",
    "    else:\n",
    "        lr = initial_lr / 4\n",
    "#     lr = 0.001\n",
    "    return lr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data():\n",
    "    dsize = 96\n",
    "    path_x = \"data/train/IMG/\"\n",
    "    path_y = \"data/train/PTS/\"\n",
    "    train_num = 9000#sum([len(x) for _, _, x in os.walk(os.path.dirname())])  \n",
    "    print(\"train_num: \", train_num)\n",
    "    image_train = np.zeros((train_num,dsize,dsize,3)) \n",
    "    label_train = np.zeros((train_num,202)) \n",
    "    for i in range(train_num):\n",
    "        points = read_points(path_y + str(i) + \".pts\")\n",
    "        points = np.array(points)\n",
    "        label_train[i] = points.reshape(1,202)\n",
    "        img = image.load_img(path_x + str(i) + \".jpg\", target_size = (dsize,dsize))\n",
    "        x = image.img_to_array(img)\n",
    "        gray = x.reshape((dsize, dsize,3))                 \n",
    "        image_train[i] = gray\n",
    "    index = [i for i in range(len(image_train))]  \n",
    "    np.random.shuffle(index) \n",
    "    image_train = image_train[index]\n",
    "    label_train = label_train[index]\n",
    "    return image_train, label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_num: ', 9000)\n",
      "('image_train:', '(9000, 96, 96, 3)')\n",
      "('label_train:', '(9000, 202)')\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 48, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 46, 46, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 44, 44, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 22, 22, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 20, 20, 64)   36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 18, 18, 64)   36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 128)    73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 128)    147584      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 2, 2, 128)    147584      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2, 2, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 2, 128)    147584      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2, 2, 128)    0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2, 2, 128)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 128)    147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 256)    0           add_1[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 128)    295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 202)          51914       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,272,650\n",
      "Trainable params: 1,272,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('image_train:', '(9000, 96, 96, 3)')\n",
      "('label_train:', '(9000, 202)')\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 6s 781us/step - loss: 4.0192e-05 - acc: 0.9276 - val_loss: 3.0322e-05 - val_acc: 0.9456\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 4s 564us/step - loss: 1.5525e-05 - acc: 0.9329 - val_loss: 3.3767e-05 - val_acc: 0.9428\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 4s 584us/step - loss: 1.3239e-05 - acc: 0.9339 - val_loss: 2.7596e-05 - val_acc: 0.9489\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 4s 569us/step - loss: 1.2531e-05 - acc: 0.9315 - val_loss: 3.0609e-05 - val_acc: 0.9456\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 4s 548us/step - loss: 1.2137e-05 - acc: 0.9339 - val_loss: 2.6263e-05 - val_acc: 0.9494\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 4s 586us/step - loss: 1.2014e-05 - acc: 0.9353 - val_loss: 4.3070e-05 - val_acc: 0.9433\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 4s 549us/step - loss: 1.4831e-05 - acc: 0.9303 - val_loss: 2.7212e-05 - val_acc: 0.9372\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 4s 586us/step - loss: 2.4580e-05 - acc: 0.9290 - val_loss: 7.5480e-05 - val_acc: 0.9328\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 2.8693e-05 - acc: 0.9314 - val_loss: 5.5910e-05 - val_acc: 0.9478\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 4s 555us/step - loss: 3.0599e-05 - acc: 0.9337 - val_loss: 3.7495e-05 - val_acc: 0.9433\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 4s 572us/step - loss: 1.9055e-05 - acc: 0.9304 - val_loss: 2.4956e-05 - val_acc: 0.9400\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 4s 563us/step - loss: 1.8763e-05 - acc: 0.9347 - val_loss: 4.8765e-05 - val_acc: 0.9422\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 4s 538us/step - loss: 2.3286e-05 - acc: 0.9319 - val_loss: 4.2788e-05 - val_acc: 0.9483\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 2.7324e-05 - acc: 0.9336 - val_loss: 3.6625e-05 - val_acc: 0.9417\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 4s 533us/step - loss: 1.6837e-05 - acc: 0.9318 - val_loss: 3.4006e-05 - val_acc: 0.9444\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 4s 575us/step - loss: 1.7583e-05 - acc: 0.9318 - val_loss: 3.3902e-05 - val_acc: 0.9511\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 4s 559us/step - loss: 1.6442e-05 - acc: 0.9350 - val_loss: 3.7004e-05 - val_acc: 0.9450\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 4s 546us/step - loss: 1.4184e-05 - acc: 0.9350 - val_loss: 2.7213e-05 - val_acc: 0.9389\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 1.3407e-05 - acc: 0.9351 - val_loss: 3.3408e-05 - val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 4s 571us/step - loss: 1.3499e-05 - acc: 0.9358 - val_loss: 2.3215e-05 - val_acc: 0.9417\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 4s 541us/step - loss: 1.2695e-05 - acc: 0.9349 - val_loss: 3.3714e-05 - val_acc: 0.9422\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 4s 592us/step - loss: 1.2595e-05 - acc: 0.9329 - val_loss: 2.7811e-05 - val_acc: 0.9467\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 4s 552us/step - loss: 1.5431e-05 - acc: 0.9340 - val_loss: 4.6370e-05 - val_acc: 0.9456\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 4s 585us/step - loss: 1.8115e-05 - acc: 0.9356 - val_loss: 2.3832e-05 - val_acc: 0.9433\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 1.4674e-05 - acc: 0.9346 - val_loss: 4.2309e-05 - val_acc: 0.9461\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 4s 553us/step - loss: 1.7108e-05 - acc: 0.9321 - val_loss: 2.6539e-05 - val_acc: 0.9428\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 4s 566us/step - loss: 1.6355e-05 - acc: 0.9349 - val_loss: 5.0626e-05 - val_acc: 0.9350\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 4s 547us/step - loss: 1.7400e-05 - acc: 0.9318 - val_loss: 2.3007e-05 - val_acc: 0.9528\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 4s 557us/step - loss: 1.4054e-05 - acc: 0.9344 - val_loss: 5.2289e-05 - val_acc: 0.9489\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 4s 534us/step - loss: 1.3809e-05 - acc: 0.9351 - val_loss: 2.5885e-05 - val_acc: 0.9489\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 4s 558us/step - loss: 1.3903e-05 - acc: 0.9354 - val_loss: 5.7923e-05 - val_acc: 0.9444\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 4s 582us/step - loss: 1.3977e-05 - acc: 0.9344 - val_loss: 3.1986e-05 - val_acc: 0.9444\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 4s 541us/step - loss: 1.6344e-05 - acc: 0.9328 - val_loss: 6.2688e-05 - val_acc: 0.9439\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 4s 574us/step - loss: 1.9534e-05 - acc: 0.9333 - val_loss: 2.4757e-05 - val_acc: 0.9356\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 1.0915e-05 - acc: 0.9333 - val_loss: 5.5591e-05 - val_acc: 0.9478\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 4s 566us/step - loss: 1.5099e-05 - acc: 0.9358 - val_loss: 2.4955e-05 - val_acc: 0.9411\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 4s 537us/step - loss: 1.3879e-05 - acc: 0.9337 - val_loss: 6.1614e-05 - val_acc: 0.9539\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 4s 580us/step - loss: 1.5589e-05 - acc: 0.9337 - val_loss: 2.4205e-05 - val_acc: 0.9483\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 4s 557us/step - loss: 1.2890e-05 - acc: 0.9356 - val_loss: 6.9183e-05 - val_acc: 0.9417\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 4s 547us/step - loss: 1.3932e-05 - acc: 0.9356 - val_loss: 3.9653e-05 - val_acc: 0.9306\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 4s 533us/step - loss: 1.6664e-05 - acc: 0.9365 - val_loss: 6.5224e-05 - val_acc: 0.9367\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 4s 588us/step - loss: 2.1031e-05 - acc: 0.9308 - val_loss: 2.7942e-05 - val_acc: 0.9489\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 4s 564us/step - loss: 1.2237e-05 - acc: 0.9361 - val_loss: 4.6076e-05 - val_acc: 0.9456\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 4s 600us/step - loss: 2.1277e-05 - acc: 0.9332 - val_loss: 2.9355e-05 - val_acc: 0.9489\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 1.5579e-05 - acc: 0.9332 - val_loss: 8.3959e-05 - val_acc: 0.9394\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s 576us/step - loss: 1.2988e-05 - acc: 0.9350 - val_loss: 5.0358e-05 - val_acc: 0.9311\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 4s 555us/step - loss: 1.2078e-05 - acc: 0.9368 - val_loss: 5.5906e-05 - val_acc: 0.9417\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 4s 568us/step - loss: 1.0757e-05 - acc: 0.9347 - val_loss: 2.7499e-05 - val_acc: 0.9467\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 4s 542us/step - loss: 9.9891e-06 - acc: 0.9337 - val_loss: 5.0421e-05 - val_acc: 0.9472\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 4s 584us/step - loss: 1.0154e-05 - acc: 0.9360 - val_loss: 2.6737e-05 - val_acc: 0.9539\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s 557us/step - loss: 1.0455e-05 - acc: 0.9346 - val_loss: 6.2382e-05 - val_acc: 0.9494\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 4s 552us/step - loss: 1.2406e-05 - acc: 0.9328 - val_loss: 2.6533e-05 - val_acc: 0.9417\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 4s 565us/step - loss: 1.1423e-05 - acc: 0.9361 - val_loss: 9.0217e-05 - val_acc: 0.9428\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 4s 534us/step - loss: 1.7391e-05 - acc: 0.9344 - val_loss: 2.8036e-05 - val_acc: 0.9439\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 4s 558us/step - loss: 1.4869e-05 - acc: 0.9337 - val_loss: 1.2524e-04 - val_acc: 0.9367\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 4s 581us/step - loss: 1.9552e-05 - acc: 0.9339 - val_loss: 3.1115e-05 - val_acc: 0.9472\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 4s 542us/step - loss: 1.3569e-05 - acc: 0.9347 - val_loss: 7.2991e-05 - val_acc: 0.9356\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 4s 541us/step - loss: 1.5641e-05 - acc: 0.9339 - val_loss: 3.2333e-05 - val_acc: 0.9494\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s 603us/step - loss: 1.3743e-05 - acc: 0.9360 - val_loss: 9.9584e-05 - val_acc: 0.9400\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 4s 591us/step - loss: 1.4869e-05 - acc: 0.9358 - val_loss: 3.6174e-05 - val_acc: 0.9472\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 4s 544us/step - loss: 1.1476e-05 - acc: 0.9347 - val_loss: 6.9242e-05 - val_acc: 0.9361\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s 582us/step - loss: 1.0119e-05 - acc: 0.9365 - val_loss: 3.8157e-05 - val_acc: 0.9489\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 4s 530us/step - loss: 1.0317e-05 - acc: 0.9354 - val_loss: 7.4929e-05 - val_acc: 0.9472\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 4s 550us/step - loss: 1.0534e-05 - acc: 0.9357 - val_loss: 3.3077e-05 - val_acc: 0.9489\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 4s 542us/step - loss: 1.2092e-05 - acc: 0.9337 - val_loss: 8.6368e-05 - val_acc: 0.9439\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 4s 563us/step - loss: 1.0105e-05 - acc: 0.9376 - val_loss: 1.0738e-04 - val_acc: 0.9478\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 4s 561us/step - loss: 1.5302e-05 - acc: 0.9343 - val_loss: 9.8337e-05 - val_acc: 0.9417\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 4s 569us/step - loss: 1.4404e-05 - acc: 0.9336 - val_loss: 3.4558e-05 - val_acc: 0.9483\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 4s 540us/step - loss: 1.1231e-05 - acc: 0.9358 - val_loss: 1.0493e-04 - val_acc: 0.9494\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 4s 569us/step - loss: 1.5005e-05 - acc: 0.9350 - val_loss: 3.5565e-05 - val_acc: 0.9344\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 4s 546us/step - loss: 1.2135e-05 - acc: 0.9375 - val_loss: 8.2741e-05 - val_acc: 0.9450\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 4s 573us/step - loss: 1.2485e-05 - acc: 0.9333 - val_loss: 3.7471e-05 - val_acc: 0.9478\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 4s 570us/step - loss: 1.2306e-05 - acc: 0.9347 - val_loss: 9.2534e-05 - val_acc: 0.9450\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 4s 577us/step - loss: 1.2758e-05 - acc: 0.9365 - val_loss: 3.8423e-05 - val_acc: 0.9444\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 4s 596us/step - loss: 1.1083e-05 - acc: 0.9364 - val_loss: 9.0525e-05 - val_acc: 0.9461\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s 543us/step - loss: 1.1233e-05 - acc: 0.9364 - val_loss: 3.9042e-05 - val_acc: 0.9444\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 1.1144e-05 - acc: 0.9364 - val_loss: 1.0546e-04 - val_acc: 0.9422\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 4s 568us/step - loss: 1.2459e-05 - acc: 0.9360 - val_loss: 3.6870e-05 - val_acc: 0.9433\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 4s 556us/step - loss: 1.0875e-05 - acc: 0.9353 - val_loss: 1.0529e-04 - val_acc: 0.9472\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 4s 605us/step - loss: 1.2194e-05 - acc: 0.9375 - val_loss: 3.9355e-05 - val_acc: 0.9483\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 1.0657e-05 - acc: 0.9363 - val_loss: 9.6339e-05 - val_acc: 0.9411\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 4s 568us/step - loss: 1.1166e-05 - acc: 0.9347 - val_loss: 4.1022e-05 - val_acc: 0.9450\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 4s 554us/step - loss: 1.0699e-05 - acc: 0.9332 - val_loss: 1.1514e-04 - val_acc: 0.9406\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 4s 570us/step - loss: 1.3942e-05 - acc: 0.9350 - val_loss: 4.1837e-05 - val_acc: 0.9433\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 4s 557us/step - loss: 9.7976e-06 - acc: 0.9363 - val_loss: 6.2560e-05 - val_acc: 0.9383\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 1.3604e-05 - acc: 0.9346 - val_loss: 4.8121e-05 - val_acc: 0.9461\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 4s 555us/step - loss: 1.0958e-05 - acc: 0.9344 - val_loss: 1.2469e-04 - val_acc: 0.9478\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 4s 539us/step - loss: 1.3585e-05 - acc: 0.9351 - val_loss: 4.1283e-05 - val_acc: 0.9489\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 4s 576us/step - loss: 9.0585e-06 - acc: 0.9354 - val_loss: 8.4312e-05 - val_acc: 0.9411\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 4s 564us/step - loss: 1.4359e-05 - acc: 0.9363 - val_loss: 4.2274e-05 - val_acc: 0.9444\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 4s 531us/step - loss: 1.1181e-05 - acc: 0.9365 - val_loss: 1.0950e-04 - val_acc: 0.9411\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 4s 545us/step - loss: 1.2394e-05 - acc: 0.9369 - val_loss: 4.5283e-05 - val_acc: 0.9489\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 4s 582us/step - loss: 1.0108e-05 - acc: 0.9342 - val_loss: 1.0137e-04 - val_acc: 0.9444\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 4s 592us/step - loss: 1.0677e-05 - acc: 0.9343 - val_loss: 4.9235e-05 - val_acc: 0.9467\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 4s 555us/step - loss: 9.9696e-06 - acc: 0.9376 - val_loss: 1.0151e-04 - val_acc: 0.9394\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 4s 557us/step - loss: 1.0464e-05 - acc: 0.9363 - val_loss: 4.9361e-05 - val_acc: 0.9489\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 4s 561us/step - loss: 9.5827e-06 - acc: 0.9351 - val_loss: 1.0365e-04 - val_acc: 0.9372\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 4s 554us/step - loss: 1.0616e-05 - acc: 0.9363 - val_loss: 4.4872e-05 - val_acc: 0.9444\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 4s 576us/step - loss: 1.1015e-05 - acc: 0.9369 - val_loss: 1.1680e-04 - val_acc: 0.9394\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 4s 571us/step - loss: 1.1512e-05 - acc: 0.9353 - val_loss: 4.9407e-05 - val_acc: 0.9389\n",
      "Model save done!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_train, label_train = input_data()  \n",
    "image_train = image_train.astype('float32')\n",
    "label_train = label_train.astype('float32')\n",
    "image_train /= 255.0\n",
    "# label_train /= 128.0\n",
    "print(\"image_train:\", str(image_train.shape))\n",
    "print(\"label_train:\", str(label_train.shape))\n",
    "K.clear_session()\n",
    "dsize = 96\n",
    "model = cnn_facealignment(size=(dsize,dsize,3))\n",
    "# model = load_model(\"model/face_alignment.h5\")\n",
    "#model =  multi_gpu_model(model, use_gpu_num)\n",
    "model.summary()#打印模型概况\n",
    "model.compile(optimizer = \"adam\", loss = 'mse',  metrics = [\"accuracy\"])\n",
    "history = LossHistory()\n",
    "print(\"image_train:\", str(image_train.shape))\n",
    "print(\"label_train:\", str(label_train.shape))\n",
    "lr = LearningRateScheduler(step_decay)\n",
    "checkpoint = ModelCheckpoint(filepath='model/face_alignment.h5',monitor='val_loss',mode='auto' ,save_best_only='True')\n",
    "callback_lists=[checkpoint,history, lr]\n",
    "model.fit(image_train, label_train,epochs=100,verbose=1,validation_split=0.2, shuffle=True,batch_size=32,callbacks=callback_lists)\n",
    "model.save(\"model/face_alignment.h5\")\n",
    "print(\"Model save done!\")\n",
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 26 variables.\n",
      "INFO:tensorflow:Converted 26 variables to const ops.\n",
      "Model Imported. Visualize by running: tensorboard --logdir=/home/shuofeng/AIProject/FaceAlignment/trans_model\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import os.path as osp\n",
    "from keras import backend as K\n",
    "\n",
    "#路径参数\n",
    "input_path = 'input path'\n",
    "weight_file = 'face_alignment.h5'\n",
    "weight_file_path = osp.join(input_path,weight_file)\n",
    "output_graph_name = weight_file[:-3] + '.pb'\n",
    "#转换函数\n",
    "def h5_to_pb(h5_model,output_dir,model_name,out_prefix = \"output_\",log_tensorboard = True):\n",
    "    if osp.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "    out_nodes = []\n",
    "    for i in range(len(h5_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(h5_model.output[i],out_prefix + str(i + 1))\n",
    "    sess = K.get_session()\n",
    "    from tensorflow.python.framework import graph_util,graph_io\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "    main_graph = graph_util.convert_variables_to_constants(sess,init_graph,out_nodes)\n",
    "    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)\n",
    "    if log_tensorboard:\n",
    "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(osp.join(output_dir,model_name),output_dir)\n",
    "#输出路径\n",
    "output_dir = osp.join(os.getcwd(),\"trans_model\")\n",
    "#加载模型\n",
    "# h5_model = load_model(weight_file_path)\n",
    "h5_to_pb(model,output_dir = output_dir,model_name = output_graph_name)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
